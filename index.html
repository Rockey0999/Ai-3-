<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Simple Face Detector</title>
    <script defer src="https://cdn.jsdelivr.net/npm/@vladmandic/face-api/dist/face-api.js"></script>
    <style>
        body { margin: 0; display: flex; justify-content: center; align-items: center; height: 100vh; background: #222; }
        canvas { position: absolute; }
        video { border-radius: 10px; box-shadow: 0 0 20px rgba(0,0,0,0.5); }
    </style>
</head>
<body>

    <video id="video" width="720" height="560" autoplay muted></video>

    <script>
        const video = document.getElementById('video');

        // 1. Load the models and start video
        Promise.all([
            face-api.nets.tinyFaceDetector.loadFromUri('https://raw.githubusercontent.com/ml5js/ml5-data-and-models/main/models/faceapi/weights/'),
        ]).then(startVideo);

        function startVideo() {
            navigator.mediaDevices.getUserMedia({ video: {} })
                .then(stream => video.srcObject = stream)
                .catch(err => console.error(err));
        }

        video.addEventListener('play', () => {
            const canvas = face-api.createCanvasFromMedia(video);
            document.body.append(canvas);
            const displaySize = { width: video.width, height: video.height };
            face-api.matchDimensions(canvas, displaySize);

            setInterval(async () => {
                const detections = await face-api.detectAllFaces(video, new face-api.TinyFaceDetectorOptions());
                const resizedDetections = face-api.resizeResults(detections, displaySize);
                
                canvas.getContext('2d').clearRect(0, 0, canvas.width, canvas.height);
                face-api.draw.drawDetections(canvas, resizedDetections);
            }, 100); // Runs every 100ms
        });
    </script>
</body>
</html>
