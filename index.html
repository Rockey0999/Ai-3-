<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>MoodMirror AI | Study Optimization</title>
    
    <script defer src="https://cdn.jsdelivr.net/npm/@vladmandic/face-api/dist/face-api.js"></script>
    
    <style>
        :root { --neon-green: #00ff88; --dark-bg: #0d1117; }
        body { background: var(--dark-bg); color: white; font-family: 'Segoe UI', Tahoma, sans-serif; text-align: center; margin: 0; padding: 20px; }
        .container { max-width: 800px; margin: auto; background: #161b22; padding: 20px; border-radius: 15px; border: 1px solid #30363d; }
        .video-box { position: relative; width: 640px; height: 480px; margin: auto; background: #000; border: 2px solid var(--neon-green); border-radius: 10px; overflow: hidden; }
        video, canvas { position: absolute; top: 0; left: 0; width: 100%; height: 100%; }
        .dashboard { display: grid; grid-template-columns: 1fr 1fr; gap: 15px; margin-top: 20px; }
        .card { background: #0d1117; padding: 15px; border-radius: 10px; border: 1px solid #30363d; }
        .val { font-size: 1.5em; font-weight: bold; color: var(--neon-green); margin-top: 5px; }
        #advice-panel { margin-top: 20px; padding: 15px; background: #238636; border-radius: 10px; font-weight: 500; min-height: 40px; }
        #loader { position: fixed; inset: 0; background: var(--dark-bg); z-index: 99; display: flex; align-items: center; justify-content: center; flex-direction: column; }
    </style>
</head>
<body>

<div id="loader">
    <div style="border: 4px solid #30363d; border-top: 4px solid var(--neon-green); border-radius: 50%; width: 40px; height: 40px; animation: spin 1s linear infinite;"></div>
    <h2 style="margin-top:20px;">MoodMirror AI Starting...</h2>
    <p>Please Allow Camera Access</p>
</div>

<div class="container">
    <h1>MOOD<span style="color:var(--neon-green)">MIRROR</span></h1>
    <p>Class 12 AI Project: Real-Time Emotional Detection [cite: 378, 406]</p>

    <div class="video-box">
        <video id="webcam" autoplay muted playsinline></video>
        <canvas id="overlay"></canvas>
    </div>

    <div class="dashboard">
        <div class="card">
            <div>DETECTED EMOTION</div>
            <div id="emo-label" class="val">Analyzing...</div>
        </div>
        <div class="card">
            <div>MENTAL STATE</div>
            <div id="state-label" class="val">Stable</div>
        </div>
    </div>

    <div id="advice-panel">
        <strong>ðŸ§  STUDY ADVICE:</strong> <span id="advice-text">Scanning your focus zone...</span>
    </div>
</div>

<script>
    const video = document.getElementById('webcam');
    const overlay = document.getElementById('overlay');

    // MoodMirror Logic Engine from your PDF [cite: 638-641, 650-653]
    function provideRecommendation(emotion) {
        let status = "NORMAL";
        let advice = "Maintain your rhythm. Stay hydrated!";

        if (['sad', 'angry', 'fearful'].includes(emotion)) {
            status = "FATIGUE / STRESS";
            advice = "Take a 10-minute break and do relaxation exercises."; // [cite: 650]
        } else if (emotion === 'happy') {
            status = "FLOW STATE";
            advice = "Great mood! Focus on your toughest task now."; // [cite: 651]
        } else if (emotion === 'neutral') {
            status = "STEADY FOCUS";
            advice = "Maintain steady pace; review notes for retention."; // [cite: 652]
        } else if (emotion === 'surprised') {
            status = "HIGH ALERT";
            advice = "You look engaged! Good time for new concepts."; // [cite: 703]
        }

        document.getElementById('emo-label').innerText = emotion.toUpperCase();
        document.getElementById('state-label').innerText = status;
        document.getElementById('advice-text').innerText = advice;
    }

    async function initAI() {
        // Fetching models from a high-speed CDN to avoid GitHub 404s
        const MODEL_URL = 'https://vladmandic.github.io/face-api/model/';
        
        try {
            await faceapi.nets.tinyFaceDetector.loadFromUri(MODEL_URL);
            await faceapi.nets.faceExpressionNet.loadFromUri(MODEL_URL);
            
            const stream = await navigator.mediaDevices.getUserMedia({ video: {} });
            video.srcObject = stream;
            document.getElementById('loader').style.display = 'none';
        } catch (err) {
            document.querySelector('#loader h2').innerText = "Camera Error: Please Check Permissions";
            console.error(err);
        }
    }

    video.addEventListener('play', () => {
        const displaySize = { width: video.clientWidth, height: video.clientHeight };
        faceapi.matchDimensions(overlay, displaySize);

        setInterval(async () => {
            const detection = await faceapi.detectSingleFace(video, new faceapi.TinyFaceDetectorOptions()).withFaceExpressions();
            
            if (detection) {
                const expressions = detection.expressions;
                const topEmotion = Object.keys(expressions).reduce((a, b) => expressions[a] > expressions[b] ? a : b);
                
                provideRecommendation(topEmotion);

                // Draw bounding box
                const resized = faceapi.resizeResults(detection, displaySize);
                const ctx = overlay.getContext('2d');
                ctx.clearRect(0, 0, overlay.width, overlay.height);
                faceapi.draw.drawDetections(overlay, resized);
            }
        }, 300); // 3x per second for real-time performance
    });

    initAI();
</script>

<style> @keyframes spin { 0% { transform: rotate(0deg); } 100% { transform: rotate(360deg); } } </style>
</body>
</html>
